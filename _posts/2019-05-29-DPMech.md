---
title:  "Differential Privacy Part-II: DP Mechanisms"
layout: posts
---

<p style="text-align:justify">Having gone through the importance of differential privacy and its definition , let us find a simple privacy preserving solution to the example in the previous tutorial of a small town. This article motivates with the theory with a practical example to make it more intuitive how the definition is applied to attain privacy.</p>

<p style="text-align:justify">Let us consider the query release problem where a analyst is querying a database with the two queries resulting in database without a given row (D2) and database with the given row(D1) as defined in previous tutorial. We shall again take the small town example with a little bit detail to make it realistic and give an idea of various queries that could provide an attack surface.</p>

<h2>Small Town Example</h2>

<p>A small town had 2000 people with various attributes age,net worth,highest education attained,..etc.</p>
<p>A query was performed in order to retrieve sum of net worths giving $800 million. Further , a query was performed to find the net worth distribution among those with a highest education level of X and aged above say 60 ,giving 20 people and a net worth of $220 million</p>
<b>1 year later</b>
<p>A new statistics was released with 2020 people with the same attributes</p>
<p>A similar query as before had been performed to retrieve sum of net worth of those with a highest education level of X,giving 19 people and a net worth of $130 million</p>
<p>Adversery found from the immigrants list that a person A with education level X had moved out , which allows them to infer that their net worth was $90 million</p>

<p style="text-align:justify">A basic way we could solve the problem is to add a constant to the query result or let us call it noise. Adding a constant could simply cancel out the effect and reveal the true value during differencing attacks so rather we add noise sampled from a probability distribution.</p>


<div style="text-align:center">
<img height="200px" width="450px" src="https://www.researchgate.net/profile/Arti_Arya2/publication/281467551/figure/fig1/AS:455000661991426@1485492019207/Differential-Privacy.png">
</div>

<p style="text-align:justify">Notice that when sampled from a probability distribution , when we query with just dataset D1 and D2 if the noise added is very close at both instances , there is very little privacy guarantee. But , if both the noise are in opposite direction there is a maximal privacy guarantee. So the probability of the noises added depends on the standard deviation of the distribution we sample from. Based on the above we could develop a mechanism in which we sample for D1 and always add noise in opposite direction when D2 is queried , but we want to treat even differencing attacks query as the same as any other query and want to rely on randomness being the primary source of privacy. The adversery having a knowledge of few rows in the database wont find it hard to find out such a mechanism.</p>

<p>The mean of the distribution is ideally the sensitivity of the dataset since that is the maximum noise we would need to provide privacy at worst case.</p>

<p><b>Note:</b> The article provides a high level overview and intuitive understanding of various mechanism. For more comphrehensive proofs and details check out the book <a target="__blank" href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf">Algorithmic Foundations of Differential Privacy</a></p>

<h2>Laplace Mechanism</h2>

<div style="text-align:center">
<img height="200px" width="450px" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Laplace_distribution_pdf.svg/1280px-Laplace_distribution_pdf.svg.png">
</div>

<p style="text-align:justify">Having motivated the DP example of adding noise from a probability distribution for a given query , Laplace mechanism is a DP mechanism where you add noise sampled from a Laplacian distribution to query result. Notice that the Laplace distribution is very suitable for DP because of its sharp rise and fall which for a given standard deviation (or epsilon) has lesser chances of values being sample being close to each other.</p>

<p>Laplace distribution is given by</p>
<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/64635ef3541c2c5eaf5a15177f3023ab5563cb53">
<p>denoted by Lap(μ,b) , where μ
is the mean of the distribution and b is the standard deviation or scale. The Laplace noise we add is given by Lap(sensitivity,

<h2>Gaussian Mechanism</h2>

<p style="text-align:justify">Gaussian mechanism is a DP mechanism where you add a Gaussain noise to a given value.Laplacian noise sampled for each datapoint can be given by the distribution Lap(sensitivity/<img height="20" width="20" src="https://cdn2.iconfinder.com/data/icons/greek-latin-symbols/24/epsilon-128.png">)  Higher the sensitivity of given datapoint larger the noise. This also implies that DP is useful only when the databases are large enough since for smaller database a promising utility-privacy tradeoff cannot be made.</p>


<div style="text-align:center">
<img height="200px" width="450px" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/2880px-Normal_Distribution_PDF.svg.png">
</div>

<p>The above is a Laplacian distribution. It is a common tool in DP due to its sharp peak</p>

<h2>Counting Query</h2>
<p style="text-align:justify">Counting queries are simple queries where the count of instances having particular attributes are retrieved. Since each individual row contributes a instance of one by itself , counting queries have a sensitivity of 1. We can mask this by using the Laplace mechanism.

<h2>Histogram Query</h2>
<center>
<img height="200px" width="300px" src="https://png.pngtree.com/svg/20170418/759297958b.png">
</center>
<p style="text-align:justify">Historgram queries are queries in which the output consists of disjoint cells representing counts over range of values. Since each cell value changes by addition/removal of a row of data it also has a sensitivity of 1. To each histogram cell we add a indepedently draw Laplace noise.
</p>

<h2>Noisy Max</h2>
<p style="text-align:justify">Report maximum value after adding noise to the data using Laplacian or Gaussian Mechanism. Result of the mechanism is also called LNMax or GNMax(Laplacian or Gaussian Noise Maximum). From priniciple of Total Information Recovery we can keep the maximum value private but only report the index of the values.</p>
<h2>Exponential Mechanism</h2>
<p style="text-align:justify">Exponential Mechanism can be useful when perturbation of the values by themselves could lead to decreased utility. So instead from a possible range of values from private dataset for a query , we select the value with probability of normalized exponential of utility score. Utility is a function which gives how useful a given range of value is to a query. Exponential could be a great way to discount for utility , selecting values with higher utility and discarding values with lower utility. It also ensures when there exists values of almost equal utility the utility guarantees are still as high as possible while maintaing privacy
To learn more about Exponential mechanism watch this amazing <a href="https://www.youtube.com/watch?v=-BmTopi6faY"></a> talk by  ... in Microsoft Research.</p>
<p>In exponential mechanism the probability of a given choice/number is given by exponential of a scoring function. If two or more choices have almost the same scores they have almost equal chances of being randomly picked which sacrifices utility to a certain extent but by a small loss since score functions of both are nearly equal. But , having such choices also provides a privacy bound.</p>


<p style="text-align:justify">Check out <a href="https://kamathhrishi.github.io/Blog/Posts/DPComposition">Part-III</a> of the tutorials where I will explain how DP algorithms privacy guarantees hold good over multiple queries</p>
