---
title:  "Differential Privacy Part-II: DP Mechanisms"
layout: posts
---

<p style="text-align:justify">Having gone through the importance of differential privacy and its definition , this article motivates the theory with a practical example to make it more intuitive how the definition is applied to attain privacy.The small town example in this previous article is just to develop an intuitive understanding of why DP would be important.In practice , for DP to be effective you would need a really large database such that the <b>law of large numbers</b> work. The law of large numbers is a law from statistics which proves that even in presence of some noisy measurements, the result of a statistic would converge to the true value(or very close to).</p>

<p style="text-align:justify">Let us consider the query release problem where a analyst is querying a database with the two queries resulting in database without a given row (D2) and database with the given row(D1) as defined in previous tutorial.</p>

<div style="text-align:center">
<img height="200px" width="450px" src="https://www.researchgate.net/profile/Arti_Arya2/publication/281467551/figure/fig1/AS:455000661991426@1485492019207/Differential-Privacy.png">
</div>

<p style="text-align:justify">
The previous tutorial defined DP as two probability distributions being close to each other by a factor of exp(epsilon).
 
Notice that when sampled from a probability distribution , when we query with just dataset D1 and D2 if the noise added is very close at both instances , there is very little privacy guarantee. But , if both the noise are in opposite direction there is a maximal privacy guarantee. So the probability of the noises added depends on the standard deviation of the distribution we sample from. Based on the above we could develop a mechanism in which we sample for D1 and always add noise in opposite direction when D2 is queried , but we want to develop a generalized querying mechanism where we treat even differencing attacks query as the same as any other query. The adversery having a knowledge of few rows in the database wont find it hard to find out such a mechanism. We rely on DP being a randomized mechanism.</p>

<p><b>Note:</b> The article provides a high level overview and intuitive understanding of various mechanism. For more comphrehensive proofs and details check out the book <a target="__blank" href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf">Algorithmic Foundations of Differential Privacy</a></p>

<h2>Laplace Mechanism</h2>

<div style="text-align:center">
<img height="200px" width="450px" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Laplace_distribution_pdf.svg/1280px-Laplace_distribution_pdf.svg.png">
</div>

<p style="text-align:justify">Having motivated the DP example of adding noise from a probability distribution for a given query , Laplace mechanism is a DP mechanism where you add noise sampled from a Laplacian distribution to query result. Notice that the Laplace distribution is very suitable for DP because of its sharp rise and fall which for a given standard deviation (or epsilon) has lesser chances of values being sample being close to each other.</p>

<p>Laplace distribution is given by</p>
<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/64635ef3541c2c5eaf5a15177f3023ab5563cb53">
<p>denoted by Lap(μ,b) , where μ
is the mean of the distribution and b is the standard deviation or scale. The Laplace noise we add is given by Lap(0,sensitivity/epsilon). This gives a privacy guarantee of DP(epsilon,0).</p>

<h2>Counting Query</h2>
<p style="text-align:justify">Counting queries are simple queries where the count of instances having particular attributes are retrieved. Since each individual row contributes a instance of one by itself , counting queries have a sensitivity of 1. We can mask this by using the Laplace mechanism.
<center>
<img height="200px" width="300px" src="https://png.pngtree.com/svg/20170418/759297958b.png">
</center>
<p>When we report the maximum of the counting query upon noise each of the count, we call it <b>noisy max</b>.
</p>
<h2>Exponential Mechanism</h2>
<p style="text-align:justify">Exponential Mechanism can be useful when perturbation of the values by themselves could lead to decreased utility. So instead from a possible range of values from private dataset for a query , we select the value with probability of normalized exponential of utility score. Utility is a function which gives how useful a given range of value is to a query. Exponential could be a great way to discount for utility , selecting values with higher utility and discarding values with lower utility. It also ensures when there exists values of almost equal utility the utility guarantees are still as high as possible while maintaing privacy
To learn more about Exponential mechanism watch this amazing <a href="https://www.youtube.com/watch?v=-BmTopi6faY"></a> talk by  ... in Microsoft Research.</p>
<p style="text-align:justify">In exponential mechanism the probability of a given choice/number is given by exponential of a scoring function. If two or more choices have almost the same scores they have almost equal chances of being randomly picked which sacrifices utility to a certain extent but by a small loss since score functions of both are nearly equal. But , having such choices also provides a privacy bound.</p>

<p style="text-align:justify">
Another major property of DP is <b>Composition</b>. Composition not only has a way to quantify how privacy degrades over a single mechanism or query but a series of mechanism or queries. Simplest rule of them is basic composition , which states that if k DP algorithms are run the privacy is now
 DP(k<img height="20" width="20" src="https://camo.githubusercontent.com/fbcc26741027732b93efb1ba96c51dd79b6dc404/68747470733a2f2f63646e322e69636f6e66696e6465722e636f6d2f646174612f69636f6e732f677265656b2d6c6174696e2d73796d626f6c732f32342f657073696c6f6e2d3132382e706e67">,k<img height="20" width="20" src="https://camo.githubusercontent.com/ac046ade980b5e0d68df1ad5a1ce38e0e6ed48a6/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f392f39662f477265656b5f6c635f64656c74612e7376672f3132303070782d477265656b5f6c635f64656c74612e7376672e706e67">).
</p>

I will explain composition in detail in a future article.

Epsilon delta definition of differential privacy
<br/>
<br/>
<div style="text-align:center">
<img height="400px" width="400px" src="https://camo.githubusercontent.com/37263db5c9094e38357fa125e8aec8207f7320b4/68747470733a2f2f692e6962622e636f2f3368786a36316d2f44502d657073696c6f6e2d64656c74612e706e67">
</div>
<br />

<p style="text-align:justify">Check out <a href="https://kamathhrishi.github.io/Blog/Posts/DPComposition">Part-III</a> of the tutorials where I will explain how DP algorithms privacy guarantees hold good over multiple queries</p>
